{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81c2cafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: version mismatch between CFITSIO header (v40200) and linked library (v34700).\n",
      "\n",
      "\n",
      "WARNING: version mismatch between CFITSIO header (v40200) and linked library (v34700).\n",
      "\n",
      "\n",
      "WARNING: version mismatch between CFITSIO header (v40200) and linked library (v34700).\n",
      "\n",
      "/Users/vytis/anaconda3/lib/python3.10/site-packages/gbm/plot/lal_post_subs.py:184: UserWarning: Basemap not installed. Some functionality not available.\n",
      "  warnings.warn('Basemap not installed. Some functionality not available.')\n"
     ]
    }
   ],
   "source": [
    "from gbm.data import Trigdat\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from gbm.plot import Lightcurve\n",
    "\n",
    "from gbm import test_data_dir\n",
    "from gbm.data import TTE\n",
    "from gbm.plot import Spectrum\n",
    "import matplotlib.pyplot as plt\n",
    "from gbm.data.primitives import TimeBins, EnergyBins\n",
    "from gbm.data.primitives import TimeEnergyBins\n",
    "\n",
    "from gbm.binning.unbinned import bin_by_time\n",
    "import numpy as np\n",
    "\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.ndimage import median_filter\n",
    "import pywt\n",
    "#from pyrobust import pca\n",
    "from scipy.ndimage import binary_erosion, binary_dilation\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "from gbm.finder import TriggerCatalog, TriggerFtp\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8007ae89",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Catalog from HEASARC via w3query.pl...\n",
      "Finished in 7 s\n",
      "Downloading TTE files for GRB bn120403857 (2012-04-03 20:33:58.493)\n",
      "Connection appears to have failed.  Attempting to reconnect...\n",
      "Reconnected.\n",
      "glg_trigdat_all_bn120403857_v01.fit [==============================] 100.00%\n",
      "glg_tte_b0_bn120403857_v00.fit [==============================] 100.00%\n",
      "glg_tte_b1_bn120403857_v00.fit [==============================] 100.00%\n",
      "glg_tte_n0_bn120403857_v00.fit [==============================] 100.00%\n",
      "glg_tte_n1_bn120403857_v00.fit [==============================] 100.00%\n",
      "glg_tte_n2_bn120403857_v00.fit [==============================] 100.00%\n",
      "glg_tte_n3_bn120403857_v00.fit [==============================] 100.00%\n",
      "glg_tte_n4_bn120403857_v00.fit [==============================] 100.00%\n",
      "glg_tte_n5_bn120403857_v00.fit [==============================] 100.00%\n",
      "glg_tte_n6_bn120403857_v00.fit [==============================] 100.00%\n",
      "glg_tte_n7_bn120403857_v00.fit [==============================] 100.00%\n",
      "glg_tte_n8_bn120403857_v00.fit [==============================] 100.00%\n",
      "glg_tte_n9_bn120403857_v00.fit [==============================] 100.00%\n",
      "glg_tte_na_bn120403857_v00.fit [==============================] 100.00%\n",
      "glg_tte_nb_bn120403857_v00.fit [==============================] 100.00%\n",
      "Download complete for GRB bn120403857\n",
      "\n",
      "Image for time range -15 to 15 successfully created.\n",
      "Image for time range -50 to 50 successfully created.\n",
      "Image for time range -150 to 150 successfully created.\n",
      "Downloading TTE files for GRB bn140912846 (2014-09-12 20:18:03.669)\n",
      "Connection appears to have failed.  Attempting to reconnect...\n",
      "Reconnected.\n",
      "glg_trigdat_all_bn140912846_v01.fit [==============================] 100.00%\n",
      "glg_tte_b0_bn140912846_v00.fit [==============================] 100.00%\n",
      "glg_tte_b1_bn140912846_v00.fit [==============================] 100.00%\n",
      "glg_tte_n0_bn140912846_v00.fit [==============================] 100.00%\n",
      "glg_tte_n1_bn140912846_v00.fit [==============================] 100.00%\n",
      "glg_tte_n2_bn140912846_v00.fit [==============================] 100.00%\n",
      "glg_tte_n3_bn140912846_v00.fit [==============================] 100.00%\n",
      "glg_tte_n4_bn140912846_v00.fit [==============================] 100.00%\n",
      "glg_tte_n5_bn140912846_v00.fit [==============================] 100.00%\n",
      "glg_tte_n6_bn140912846_v00.fit [==============================] 100.00%\n",
      "glg_tte_n7_bn140912846_v00.fit [==============================] 100.00%\n",
      "glg_tte_n8_bn140912846_v00.fit [==============================] 100.00%\n",
      "glg_tte_n9_bn140912846_v00.fit [==============================] 100.00%\n",
      "glg_tte_na_bn140912846_v00.fit [==============================] 100.00%\n",
      "glg_tte_nb_bn140912846_v00.fit [==============================] 100.00%\n",
      "Download complete for GRB bn140912846\n",
      "\n",
      "Image for time range -15 to 15 successfully created.\n",
      "Image for time range -50 to 50 successfully created.\n",
      "Image for time range -150 to 150 successfully created.\n",
      "Downloading TTE files for GRB bn120227725 (2012-02-27 17:24:41.054)\n",
      "Connection appears to have failed.  Attempting to reconnect...\n",
      "Reconnected.\n",
      "glg_trigdat_all_bn120227725_v01.fit [==============================] 100.00%\n",
      "glg_tte_b0_bn120227725_v00.fit [==============================] 100.00%\n",
      "glg_tte_b1_bn120227725_v00.fit [==============================] 100.00%\n",
      "glg_tte_n0_bn120227725_v00.fit [==============================] 100.00%\n",
      "glg_tte_n1_bn120227725_v00.fit [==============================] 100.00%\n",
      "glg_tte_n2_bn120227725_v00.fit [==============================] 100.00%\n",
      "glg_tte_n3_bn120227725_v00.fit [==============================] 100.00%\n",
      "glg_tte_n4_bn120227725_v00.fit [==============================] 100.00%\n",
      "glg_tte_n5_bn120227725_v00.fit [==============================] 100.00%\n",
      "glg_tte_n6_bn120227725_v00.fit [==============================] 100.00%\n",
      "glg_tte_n7_bn120227725_v00.fit [==============================] 100.00%\n",
      "glg_tte_n8_bn120227725_v00.fit [==============================] 100.00%\n",
      "glg_tte_n9_bn120227725_v00.fit [==============================] 100.00%\n",
      "glg_tte_na_bn120227725_v00.fit [==============================] 100.00%\n",
      "glg_tte_nb_bn120227725_v00.fit [==============================] 100.00%\n",
      "Download complete for GRB bn120227725\n",
      "\n",
      "Error processing TTE data for b1: '_ValidHDU' object has no attribute 'data'\n",
      "AxisError occurred while processing percentile for detector b1: axis 0 is out of bounds for array of dimension 0\n",
      "Error processing TTE data for b1: '_ValidHDU' object has no attribute 'data'\n",
      "Image for time range -15 to 15 successfully created.\n",
      "Error processing TTE data for b1: '_ValidHDU' object has no attribute 'data'\n",
      "AxisError occurred while processing percentile for detector b1: axis 0 is out of bounds for array of dimension 0\n",
      "Error processing TTE data for b1: '_ValidHDU' object has no attribute 'data'\n",
      "Image for time range -50 to 50 successfully created.\n",
      "Error processing TTE data for b1: '_ValidHDU' object has no attribute 'data'\n",
      "AxisError occurred while processing percentile for detector b1: axis 0 is out of bounds for array of dimension 0\n",
      "Error processing TTE data for b1: '_ValidHDU' object has no attribute 'data'\n",
      "Image for time range -150 to 150 successfully created.\n",
      "Downloading TTE files for GRB bn140630748 (2014-06-30 17:56:48.910)\n",
      "Connection appears to have failed.  Attempting to reconnect...\n",
      "Reconnected.\n",
      "glg_trigdat_all_bn140630748_v01.fit [==============================] 100.00%\n",
      "glg_tte_b0_bn140630748_v00.fit [==============================] 100.00%\n",
      "glg_tte_b1_bn140630748_v00.fit [================              ] 56.17%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glg_tte_n0_bn140630748_v00.fit [==============================] 100.00%\n",
      "glg_tte_n1_bn140630748_v00.fit [==============================] 100.00%\n",
      "glg_tte_n2_bn140630748_v00.fit [==============================] 100.00%\n",
      "glg_tte_n3_bn140630748_v00.fit [==============================] 100.00%\n",
      "glg_tte_n4_bn140630748_v00.fit [==============================] 100.00%\n",
      "glg_tte_n5_bn140630748_v00.fit [==============================] 100.00%\n",
      "glg_tte_n6_bn140630748_v00.fit [==============================] 100.00%\n",
      "glg_tte_n7_bn140630748_v00.fit [==============================] 100.00%\n",
      "glg_tte_n8_bn140630748_v00.fit [==============================] 100.00%\n",
      "glg_tte_n9_bn140630748_v00.fit [==============================] 100.00%\n",
      "glg_tte_na_bn140630748_v00.fit [==============================] 100.00%\n",
      "glg_tte_nb_bn140630748_v00.fit [=================             ] 59.90%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for time range -15 to 15 successfully created.\n",
      "Image for time range -50 to 50 successfully created.\n",
      "Image for time range -150 to 150 successfully created.\n",
      "Downloading TTE files for GRB bn230524357 (2023-05-24 08:34:31.512)\n",
      "Connection appears to have failed.  Attempting to reconnect...\n",
      "Reconnected.\n",
      "glg_trigdat_all_bn230524357_v02.fit [==============================] 100.00%\n",
      "File glg_trigdat_all_bn230524357_v01.fit does not exist. Trying next version.\n",
      "File glg_trigdat_all_bn230524357_v00.fit does not exist. Trying next version.\n",
      "glg_tte_b0_bn230524357_v00.fit [==============================] 100.00%\n",
      "glg_tte_b1_bn230524357_v00.fit [==============================] 100.00%\n",
      "glg_tte_n0_bn230524357_v00.fit [==============================] 100.00%\n",
      "glg_tte_n1_bn230524357_v00.fit [==============================] 100.00%\n",
      "glg_tte_n2_bn230524357_v00.fit [==============================] 100.00%\n",
      "glg_tte_n3_bn230524357_v00.fit [==============================] 100.00%\n",
      "glg_tte_n4_bn230524357_v00.fit [==============================] 100.00%\n",
      "glg_tte_n5_bn230524357_v00.fit [==============================] 100.00%\n",
      "glg_tte_n6_bn230524357_v00.fit [==============================] 100.00%\n",
      "glg_tte_n7_bn230524357_v00.fit [==============================] 100.00%\n",
      "glg_tte_n8_bn230524357_v00.fit [==============================] 100.00%\n",
      "glg_tte_n9_bn230524357_v00.fit [==============================] 100.00%\n",
      "glg_tte_na_bn230524357_v00.fit [==============================] 100.00%\n",
      "glg_tte_nb_bn230524357_v00.fit [==============================] 100.00%\n",
      "Download complete for GRB bn230524357\n",
      "\n",
      "Image for time range -15 to 15 successfully created.\n",
      "Image for time range -50 to 50 successfully created.\n",
      "Image for time range -150 to 150 successfully created.\n"
     ]
    }
   ],
   "source": [
    "def polynomial(x, *coeffs):\n",
    "    return np.polyval(coeffs, x)\n",
    "\n",
    "def subtract_background_iteratively(bin_times, bin_counts, degree=2, iterations=2):\n",
    "    corrected_counts = bin_counts.copy()\n",
    "    for iteration in range(iterations):\n",
    "        for i in range(corrected_counts.shape[0]):\n",
    "            background_mask = np.logical_or(bin_times < 0, bin_times > 20)\n",
    "            coeffs, _ = curve_fit(polynomial, bin_times[background_mask], corrected_counts[i, background_mask], p0=[1] * (degree + 1))\n",
    "            background = polynomial(bin_times, *coeffs)\n",
    "            corrected_counts[i, :] -= background\n",
    "            corrected_counts[i, :] = np.clip(corrected_counts[i, :], 0, None)\n",
    "\n",
    "    noise_level = np.std(corrected_counts[:, background_mask], axis=1)\n",
    "    snr_threshold = 2\n",
    "    for i in range(corrected_counts.shape[0]):\n",
    "        signal = corrected_counts[i, :]\n",
    "        noise = noise_level[i]\n",
    "        corrected_counts[i, :] = np.where(signal > snr_threshold * noise, signal, 0)\n",
    "\n",
    "    return corrected_counts\n",
    "\n",
    "def process_tte_data(detector_name, bin_number, time_range, smearing_factor=0.1):\n",
    "    try:\n",
    "        tte = TTE.open(f'glg_tte_{detector_name}_{bin_number}_v00.fit')\n",
    "\n",
    "        time_sliced_tte = tte.slice_time(time_range)\n",
    "\n",
    "        eventlist = time_sliced_tte.data\n",
    "\n",
    "        bin_width = 0.2\n",
    "        bins = eventlist.bin(bin_by_time, bin_width)\n",
    "\n",
    "        bin_times = bins.time_centroids\n",
    "        bin_counts = bins.counts\n",
    "        energy = bins.energy_centroids\n",
    "\n",
    "        # Smear the bin counts\n",
    "        smeared_counts = np.copy(bin_counts)\n",
    "        for i in range(1, len(bin_counts) - 1):\n",
    "            smeared_counts[i] = (smearing_factor * bin_counts[i - 1] +\n",
    "                                 (1 - 2 * smearing_factor) * bin_counts[i] +\n",
    "                                 smearing_factor * bin_counts[i + 1])\n",
    "\n",
    "        return bin_times, smeared_counts, energy\n",
    "    except AttributeError as e:\n",
    "        print(f\"Error processing TTE data for {detector_name}: {e}\")\n",
    "        return None, None, None  # Return None values to indicate failure\n",
    "    \n",
    "time_ranges = [(-15, 15), (-50, 50), (-150, 150)]    \n",
    "\n",
    "# Step 1: Choose GRBs of Interest\n",
    "trigcat = TriggerCatalog()\n",
    "sliced_trigcat = trigcat.slice('end_time')\n",
    "\n",
    "# Step 2: Initialize Trigger Finder\n",
    "for trigger_info in sliced_trigcat.get_table(columns=('trigger_name', 'trigger_time')).tolist()[:5]:\n",
    "    trigger_name, trigger_time = trigger_info\n",
    "    print(f\"Downloading TTE files for GRB {trigger_name} ({trigger_time})\")\n",
    "    \n",
    "    # Remove \"bn\" from trigger_name\n",
    "    modified_trigger_name = trigger_name.replace(\"bn\", \"\")\n",
    "\n",
    "    # Initialize Trigger Finder\n",
    "    trig_finder = TriggerFtp(modified_trigger_name)\n",
    "\n",
    "    # Download trigdat file to the current directory\n",
    "    try:\n",
    "        trig_finder.get_trigdat('./')\n",
    "    except AttributeError as e:\n",
    "        print(f\"AttributeError occurred while downloading trigdat file for GRB {trigger_name}: {e}\")\n",
    "        continue\n",
    "      \n",
    "    # Try opening the file with v01, if not found, try v00 and v02\n",
    "    version_suffixes = ['v01', 'v00', 'v02']\n",
    "    for suffix in version_suffixes:\n",
    "        filename = f'glg_trigdat_all_{trigger_name}_{suffix}.fit'\n",
    "        try:\n",
    "            trigdat = Trigdat.open(filename)\n",
    "            trig_dets = trigdat.triggered_detectors\n",
    "            file_found = True\n",
    "            break  # If the file is successfully opened, exit the loop\n",
    "        except OSError as e:\n",
    "            if \"does not exist\" in str(e):\n",
    "                print(f\"File {filename} does not exist. Trying next version.\")\n",
    "            else:\n",
    "                raise  # Re-raise the exception if it's not related to file existence\n",
    "\n",
    "    if not file_found:\n",
    "        print(\"None of the files with the specified versions were found.\")\n",
    "    \n",
    "    # Download TTE files to the current directory\n",
    "    trig_finder.get_tte('./')\n",
    "\n",
    "    print(f\"Download complete for GRB {trigger_name}\\n\")\n",
    "\n",
    "    for time_range in time_ranges:\n",
    "        \n",
    "        time_range_dir = f'/Users/vytis/Desktop/GRB Images/TimeRange_{time_range[0]}_{time_range[1]}'\n",
    "        os.makedirs(time_range_dir, exist_ok=True)\n",
    "        \n",
    "        # Process the downloaded TTE data\n",
    "        bin_number = modified_trigger_name\n",
    "        if not bin_number.startswith('bn'):\n",
    "            bin_number = 'bn' + bin_number\n",
    "        length = \"Long\"\n",
    "        grb_name = bin_number.replace(\"bn\", \"\")\n",
    "\n",
    "        # NaI Detectors\n",
    "        na_detectors = trig_dets\n",
    "        na_counts_list = []\n",
    "        for detector in na_detectors:\n",
    "            bin_times, bin_counts, _ = process_tte_data(detector, bin_number, time_range)\n",
    "\n",
    "            # Remove the bottom 90% of counts for each column\n",
    "            percentile_90 = np.percentile(bin_counts, 90, axis=0)\n",
    "            for i in range(bin_counts.shape[1]):\n",
    "                bin_counts[:, i] = np.where(bin_counts[:, i] > percentile_90[i], bin_counts[:, i], 0)\n",
    "\n",
    "            #bin_counts_nai_corrected = subtract_background(bin_times_nai, bin_counts_nai.T).T\n",
    "            bin_counts_polynomial_filtering = subtract_background_iteratively(bin_times, bin_counts.T).T\n",
    "\n",
    "            # Set the last two rows to 0\n",
    "            bin_counts_polynomial_filtering[:, -3:] = 0\n",
    "            \n",
    "            # Normalize the filtered counts\n",
    "            bin_counts_normalized = bin_counts_polynomial_filtering / np.max(bin_counts_polynomial_filtering)\n",
    "\n",
    "            # Apply median filter\n",
    "            filtered_counts = median_filter(bin_counts_normalized, size=(2, 2))\n",
    "\n",
    "            na_counts_list.append(filtered_counts)\n",
    "\n",
    "        try:\n",
    "            # Combine processed counts from all NaI detectors\n",
    "            bin_counts_nai = np.sum(na_counts_list, axis=0)\n",
    "            filtered_counts_log_nai = np.log1p(bin_counts_nai)\n",
    "        except ValueError as e:\n",
    "            print(f\"ValueError occurred while combining detector counts: {e}\")\n",
    "            # Handle the error case by skipping the current loop iteration\n",
    "            continue\n",
    "\n",
    "        bin_times_list, _, energy_list = zip(*[process_tte_data(detector, bin_number, time_range) for detector in na_detectors])\n",
    "\n",
    "        # Combine counts from all NaI detectors\n",
    "        bin_times_nai = bin_times_list[0]\n",
    "        energy_nai = energy_list[0]\n",
    "\n",
    "        # Bismuth Detectors\n",
    "        bgo_detectors = ['b0', 'b1']\n",
    "        bgo_counts_list = []\n",
    "        for detector in bgo_detectors:\n",
    "            bin_times, bin_counts, _ = process_tte_data(detector, bin_number, time_range)\n",
    "\n",
    "            try:\n",
    "                percentile_90 = np.percentile(bin_counts, 90, axis=0)\n",
    "                for i in range(bin_counts.shape[1]):\n",
    "                    bin_counts[:, i] = np.where(bin_counts[:, i] > percentile_90[i], bin_counts[:, i], 0)\n",
    "            except np.AxisError as e:\n",
    "                print(f\"AxisError occurred while processing percentile for detector {detector}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # Normalize the filtered counts\n",
    "            bin_counts_normalized = bin_counts / np.max(bin_counts)\n",
    "\n",
    "            # Apply median filter\n",
    "            filtered_counts = median_filter(bin_counts_normalized, size=(2, 2))\n",
    "\n",
    "            bgo_counts_list.append(filtered_counts)\n",
    "\n",
    "        # Combine processed counts from all NaI detectors\n",
    "        bin_counts_bgo = np.sum(bgo_counts_list, axis=0)\n",
    "        filtered_counts_log_bgo = np.log1p(bin_counts_bgo)\n",
    "\n",
    "        bin_times_bgo, bin_counts_bgo, energy_bgo = zip(*[process_tte_data(detector, bin_number, time_range) for detector in bgo_detectors])\n",
    "\n",
    "        # Combine counts from all BGO detectors\n",
    "        bin_times_bgo_combined = bin_times_bgo[0]\n",
    "        energy_bgo_combined = energy_bgo[0]\n",
    "\n",
    "        # Create the figure\n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(10, 8))\n",
    "\n",
    "        # Plot for NaI Detectors\n",
    "        im1 = ax1.imshow(filtered_counts_log_bgo.T, aspect='auto', extent=[time_range[0], time_range[1], energy_bgo_combined.min(), energy_bgo_combined.max()], cmap='viridis', origin='lower')\n",
    "        ax1.set_ylabel('Energy (keV)')\n",
    "        ax1.set_title(f'GRB {grb_name} ({length}) Count Heat Map for Time Range {time_range[0]} to {time_range[1]}')\n",
    "        fig.colorbar(im1, ax=ax1, label='Log(Counts + 1)')\n",
    "        \n",
    "        # Plot for BGO Detectors\n",
    "        im2 = ax2.imshow(filtered_counts_log_nai.T, aspect='auto', extent=[time_range[0], time_range[1], energy_nai.min(), energy_nai.max()], cmap='viridis', origin='lower')\n",
    "        ax2.set_xlabel('Time (s)')\n",
    "        ax2.set_ylabel('Energy (keV)')\n",
    "        ax2.set_title('')\n",
    "        fig.colorbar(im2, ax=ax2, label='Log(Counts + 1)')\n",
    "\n",
    "        plt.subplots_adjust(hspace=0.01)\n",
    "        plt.savefig(os.path.join(time_range_dir, f'GRB_{grb_name}_TimeRange_{time_range[0]}_{time_range[1]}.png'))\n",
    "        plt.close()\n",
    "        print(f'Image for time range {time_range[0]} to {time_range[1]} successfully created.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4236dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "\n",
    "# Image dimensions\n",
    "img_width, img_height = 150, 150\n",
    "train_data_dir = 'path_to_training_data'\n",
    "validation_data_dir = 'path_to_validation_data'\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 800\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "# Model architecture\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Data augmentation for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# Rescaling for validation\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "# Training the model\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "# Saving the model\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bdc396",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
